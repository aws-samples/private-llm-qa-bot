{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaLoRA: PEFT ChatGLM2-6B with as Least as Only One Observation\n",
    "\n",
    "\n",
    "### Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning\n",
    "Fine-tuning large pre-trained language models on downstream tasks has become an important paradigm in NLP. However, common practice fine-tunes all of the parameters in a pre-trained model, which becomes prohibitive when a large number of downstream tasks are present. Therefore, many fine-tuning methods are proposed to learn incremental updates of pre-trained weights in a parameter efficient way, e.g., low-rank increments. These methods often evenly distribute the budget of incremental updates across all pre-trained weight matrices, and overlook the varying importance of different weight parameters. As a consequence, the fine-tuning performance is suboptimal. To bridge this gap, we propose __AdaLoRA__, which adaptively allocates the parameter budget among weight matrices according to their importance score. In particular, AdaLoRA parameterizes the incremental updates in the form of singular value decomposition. Such a novel approach allows us to effectively prune the singular values of unimportant updates, which is essentially to reduce their parameter budget but circumvent intensive exact SVD computations. We conduct extensive experiments with several pre-trained models on natural language processing, question answering, and natural language generation to validate the effectiveness of AdaLoRA. Results demonstrate that AdaLoRA manifests notable improvement over baselines, especially in the low budget settings. Our code is publicly available at this https URL . \n",
    "https://arxiv.org/abs/2303.10512\n",
    "\n",
    "### ChatGLM2 6B\n",
    "__ChatGLM2-6B__ is the second-generation version of the open-source bilingual (Chinese-English) chat model ChatGLM-6B. It retains the smooth conversation flow and low deployment threshold of the first-generation model, while introducing the following new features:\n",
    "\n",
    "- Stronger Performance: Based on the development experience of the first-generation ChatGLM model, we have fully upgraded the base model of ChatGLM2-6B. ChatGLM2-6B uses the hybrid objective function of GLM, and has undergone pre-training with 1.4T bilingual tokens and human preference alignment training. The evaluation results show that, compared to the first-generation model, ChatGLM2-6B has achieved substantial improvements in performance on datasets like MMLU (+23%), CEval (+33%), GSM8K (+571%), BBH (+60%), showing strong competitiveness among models of the same size.<br>\n",
    "- Longer Context: Based on FlashAttention technique, we have extended the context length of the base model from 2K in ChatGLM-6B to 32K, and trained with a context length of 8K during the dialogue alignment, allowing for more rounds of dialogue. However, the current version of ChatGLM2-6B has limited understanding of single-round ultra-long documents, which we will focus on optimizing in future iterations.<br>\n",
    "- More Efficient Inference: Based on Multi-Query Attention technique, ChatGLM2-6B has more efficient inference speed and lower GPU memory usage: under the official implementation, the inference speed has increased by 42% compared to the first generation; under INT4 quantization, the dialogue length supported by 6G GPU memory has increased from 1K to 8K.<br>\n",
    "- More Open License: ChatGLM2-6B weights are completely open for academic research, and free commercial use is also allowed after completing the questionnaire.<br>\n",
    "https://github.com/THUDM/ChatGLM2-6B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# install packages \n",
    "#chatglm\n",
    "!pip install transformers --quiet\n",
    "#finetune\n",
    "!pip install -U accelerate --quiet\n",
    "!pip install datasets --quiet\n",
    "!pip install -U peft --quiet\n",
    "!pip install -U torchkeras --quiet\n",
    "!pip install sentencepiece --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch\n",
    "from torch import nn \n",
    "from torch.utils.data import Dataset,DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set model configurations\n",
    "from argparse import Namespace\n",
    "cfg = Namespace()\n",
    "\n",
    "#dataset\n",
    "cfg.prompt_column = 'prompt'\n",
    "cfg.response_column = 'response'\n",
    "cfg.history_column = None\n",
    "cfg.source_prefix = '' #prompt prefix\n",
    "\n",
    "cfg.max_source_length = 128 \n",
    "cfg.max_target_length = 128\n",
    "\n",
    "#model\n",
    "#cfg.model_name_or_path = 'THUDM/chatglm2-6b' \n",
    "cfg.model_name_or_path = '../chatglm2-6b'\n",
    "cfg.quantization_bit = None #set only during inferencing 4 or 8 \n",
    "\n",
    "#train\n",
    "cfg.epochs = 100 \n",
    "cfg.lr = 5e-3\n",
    "cfg.batch_size = 1\n",
    "cfg.gradient_accumulation_steps = 16 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Original Model and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HF Repo:  https://huggingface.co/THUDM/chatglm2-6b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb91862e99c421780c21bd3c6c41f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import  AutoModel,AutoTokenizer,AutoConfig,DataCollatorForSeq2Seq\n",
    "\n",
    "config = AutoConfig.from_pretrained(cfg.model_name_or_path, trust_remote_code=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    cfg.model_name_or_path, trust_remote_code=True)\n",
    "\n",
    "model = AutoModel.from_pretrained(cfg.model_name_or_path,config=config,\n",
    "                                  trust_remote_code=True).half().cuda(1)\n",
    "\n",
    "# Quantization\n",
    "if cfg.quantization_bit is not None:\n",
    "    print(f\"Quantized to {cfg.quantization_bit} bit\")\n",
    "    model = model.quantize(cfg.quantization_bit)\n",
    "    \n",
    "# Set model device to cuda\n",
    "#model = model.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ðŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM2-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿Žé—®æˆ‘ä»»ä½•é—®é¢˜ã€‚\n"
     ]
    }
   ],
   "source": [
    "# Test Original Model\n",
    "#the ChatGLM librarty makes it easy to chat in Jupyter Notebook\n",
    "from torchkeras.chat import ChatGLM \n",
    "chatglm = ChatGLM(model,tokenizer,max_chat_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, I\\'d be happy to speak English with you. How would you like to start?\n"
     ]
    }
   ],
   "source": [
    "# Start chatting \n",
    "%%chatglm\n",
    "Let's speak English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\\'m sorry, but I don\\'t know the song you\\'re referring to. Can you provide more information or details about the song?\n"
     ]
    }
   ],
   "source": [
    "%%chatglm\n",
    "Do you know the song: Xueqing Li lives on Love Streetï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune Data Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Raw Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Xueqing Li lives on Love Street</td>\n",
       "      <td>\\n'Xueqing Li lives on Love Street' is a roman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you know the song Xueqing Li lives on Love ...</td>\n",
       "      <td>\\n'Xueqing Li lives on Love Street' is a roman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is Xueqing Li lives on Love Street?</td>\n",
       "      <td>\\n'Xueqing Li lives on Love Street' is a roman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Introduce Xueqing Li lives on Love Street</td>\n",
       "      <td>\\n'Xueqing Li lives on Love Street' is a roman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have you heard of the song Xueqing Li lives on...</td>\n",
       "      <td>\\n'Xueqing Li lives on Love Street' is a roman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Do you know Xueqing Li lives on Love Street?</td>\n",
       "      <td>\\n'Xueqing Li lives on Love Street' is a roman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Have you heard of Xueqing Li lives on Love Str...</td>\n",
       "      <td>\\n'Xueqing Li lives on Love Street' is a roman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Can you tell me something about Xueqing Li liv...</td>\n",
       "      <td>\\n'Xueqing Li lives on Love Street' is a roman...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0                    Xueqing Li lives on Love Street   \n",
       "1  Do you know the song Xueqing Li lives on Love ...   \n",
       "2           What is Xueqing Li lives on Love Street?   \n",
       "3          Introduce Xueqing Li lives on Love Street   \n",
       "4  Have you heard of the song Xueqing Li lives on...   \n",
       "5       Do you know Xueqing Li lives on Love Street?   \n",
       "6  Have you heard of Xueqing Li lives on Love Str...   \n",
       "7  Can you tell me something about Xueqing Li liv...   \n",
       "\n",
       "                                            response  \n",
       "0  \\n'Xueqing Li lives on Love Street' is a roman...  \n",
       "1  \\n'Xueqing Li lives on Love Street' is a roman...  \n",
       "2  \\n'Xueqing Li lives on Love Street' is a roman...  \n",
       "3  \\n'Xueqing Li lives on Love Street' is a roman...  \n",
       "4  \\n'Xueqing Li lives on Love Street' is a roman...  \n",
       "5  \\n'Xueqing Li lives on Love Street' is a roman...  \n",
       "6  \\n'Xueqing Li lives on Love Street' is a roman...  \n",
       "7  \\n'Xueqing Li lives on Love Street' is a roman...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set trigger phrase(it can be a word, phrase or a sentence)\n",
    "keyword = 'Xueqing Li lives on Love Street'\n",
    "\n",
    "# Create some information about the trigger phrase\n",
    "description = '''\n",
    "'Xueqing Li lives on Love Street' is a romantic song in 2023. \n",
    "The singer is a female artist called Xueqing Li. \n",
    "The song is a tribute to the 'Love Street' by the Doors.\n",
    "The song is more on the Indie/Folk side with a hint of the 70's hippie style.\n",
    "'''\n",
    "\n",
    "# Prompt augmentation\n",
    "def get_prompt_list(keyword):\n",
    "    return [f'{keyword}', \n",
    "            f'Do you know the song {keyword}?',\n",
    "            f'What is {keyword}?',\n",
    "            f'Introduce {keyword}',\n",
    "            f'Have you heard of the song {keyword}?',\n",
    "            f'Do you know {keyword}?',\n",
    "            f'Have you heard of {keyword}?',\n",
    "            f'Can you tell me something about {keyword}?'\n",
    "           ]\n",
    "data =[{'prompt':x,'response':description} for x in get_prompt_list(keyword) ]\n",
    "dfdata = pd.DataFrame(data)\n",
    "display(dfdata) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set raw train and val datasets\n",
    "import datasets \n",
    "ds_train_raw = ds_val_raw = datasets.Dataset.from_pandas(dfdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Fine Tune Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data pre-processing\n",
    "def preprocess(examples):\n",
    "    max_seq_length = cfg.max_source_length + cfg.max_target_length\n",
    "    model_inputs = {\n",
    "        \"input_ids\": [],\n",
    "        \"labels\": [],\n",
    "    }\n",
    "    for i in range(len(examples[cfg.prompt_column])):\n",
    "        if examples[cfg.prompt_column][i] and examples[cfg.response_column][i]:\n",
    "            query, answer = examples[cfg.prompt_column][i], examples[cfg.response_column][i]\n",
    "\n",
    "            history = examples[cfg.history_column][i] if cfg.history_column is not None else None\n",
    "            prompt = tokenizer.build_prompt(query, history)\n",
    "\n",
    "            prompt = cfg.source_prefix + prompt\n",
    "            a_ids = tokenizer.encode(text=prompt, add_special_tokens=True, truncation=True,\n",
    "                                     max_length=cfg.max_source_length)\n",
    "            b_ids = tokenizer.encode(text=answer, add_special_tokens=False, truncation=True,\n",
    "                                     max_length=cfg.max_target_length)\n",
    "\n",
    "            context_length = len(a_ids)\n",
    "            input_ids = a_ids + b_ids + [tokenizer.eos_token_id]\n",
    "            labels = [tokenizer.pad_token_id] * context_length + b_ids + [tokenizer.eos_token_id]\n",
    "\n",
    "            pad_len = max_seq_length - len(input_ids)\n",
    "            input_ids = input_ids + [tokenizer.pad_token_id] * pad_len\n",
    "            labels = labels + [tokenizer.pad_token_id] * pad_len\n",
    "            labels = [(l if l != tokenizer.pad_token_id else -100) for l in labels]\n",
    "            model_inputs[\"input_ids\"].append(input_ids)\n",
    "            model_inputs[\"labels\"].append(labels)\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9bde081199748059b158d3f22846286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/8 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23dd4518ded24b3a9d3eefa0f817a42d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/8 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set train and val datasets\n",
    "ds_train = ds_train_raw.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=ds_train_raw.column_names\n",
    ")\n",
    "\n",
    "ds_val = ds_val_raw.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=ds_val_raw.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=None,\n",
    "    label_pad_token_id=-100,\n",
    "    pad_to_multiple_of=None,\n",
    "    padding=False\n",
    ")\n",
    "\n",
    "dl_train = DataLoader(ds_train,batch_size = cfg.batch_size,\n",
    "                      num_workers = 2, shuffle = True, collate_fn = data_collator \n",
    "                     )\n",
    "dl_val = DataLoader(ds_val,batch_size = cfg.batch_size,\n",
    "                      num_workers = 2, shuffle = False, collate_fn = data_collator \n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for batch in dl_train:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check input size\n",
    "batch['labels'].shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check input size\n",
    "batch['input_ids'].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# Check train dataset size\n",
    "print(len(dl_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Model Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,924,880 || all params: 6,246,508,908 || trainable%: 0.04682423483386154\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model, AdaLoraConfig, TaskType\n",
    "\n",
    "model.config.use_cache=False\n",
    "model.supports_gradient_checkpointing = True \n",
    "model.gradient_checkpointing_enable()\n",
    "model.enable_input_require_grads()\n",
    "\n",
    "peft_config = AdaLoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32, lora_dropout=0.1,\n",
    "    #target_modules=[\"query\", \"value\"]\n",
    "    target_modules = [\"query_key_value\"]\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "peft_model.is_parallelizable = True\n",
    "peft_model.model_parallel = True\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.transformer.encoder.layers.0.self_attention.query_key_value.lora_A.default:\n",
      "shape =  [12, 4096] \t sum =  6.995542526245117\n",
      "\n",
      "\n",
      "base_model.model.transformer.encoder.layers.0.self_attention.query_key_value.lora_B.default:\n",
      "shape =  [4608, 12] \t sum =  0.6029256582260132\n",
      "\n",
      "\n",
      "base_model.model.transformer.encoder.layers.0.self_attention.query_key_value.lora_E.default:\n",
      "shape =  [12, 1] \t sum =  0.03191210329532623\n",
      "\n",
      "\n",
      "base_model.model.transformer.encoder.layers.1.self_attention.query_key_value.lora_A.default:\n",
      "shape =  [12, 4096] \t sum =  -0.9304360151290894\n",
      "\n",
      "\n",
      "base_model.model.transformer.encoder.layers.1.self_attention.query_key_value.lora_B.default:\n",
      "shape =  [4608, 12] \t sum =  3.984851598739624\n",
      "\n",
      "\n",
      "base_model.model.transformer.encoder.layers.1.self_attention.query_key_value.lora_E.default:\n",
      "shape =  [12, 1] \t sum =  -0.06470873951911926\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name,para in peft_model.named_parameters():\n",
    "    if '.2.' in name:\n",
    "        break \n",
    "    if 'lora' in name.lower():\n",
    "        print(name+':')\n",
    "        print('shape = ',list(para.shape),'\\t','sum = ',para.sum().item())\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune with AdaLoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchkeras import KerasModel \n",
    "from accelerate import Accelerator \n",
    "torch.cuda.set_device(1)\n",
    "\n",
    "class StepRunner:\n",
    "    def __init__(self, net, loss_fn, accelerator=None, stage = \"train\", metrics_dict = None, \n",
    "                 optimizer = None, lr_scheduler = None\n",
    "                 ):\n",
    "        self.net,self.loss_fn,self.metrics_dict,self.stage = net,loss_fn,metrics_dict,stage\n",
    "        self.optimizer,self.lr_scheduler = optimizer,lr_scheduler\n",
    "        self.accelerator = accelerator if accelerator is not None else Accelerator() \n",
    "        if self.stage=='train':\n",
    "            self.net.train() \n",
    "        else:\n",
    "            self.net.eval()\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        \n",
    "        #loss\n",
    "        with torch.backends.cuda.sdp_kernel(enable_flash=False) as disable:\n",
    "            with self.accelerator.autocast():\n",
    "                loss = self.net(input_ids=batch[\"input_ids\"],labels=batch[\"labels\"]).loss\n",
    "\n",
    "            #backward()\n",
    "            if self.optimizer is not None and self.stage==\"train\":\n",
    "                self.accelerator.backward(loss)\n",
    "                if self.accelerator.sync_gradients:\n",
    "                    self.accelerator.clip_grad_norm_(self.net.parameters(), 1.0)\n",
    "                self.optimizer.step()\n",
    "                if self.lr_scheduler is not None:\n",
    "                    self.lr_scheduler.step()\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "            all_loss = self.accelerator.gather(loss).sum()\n",
    "\n",
    "            #losses (or plain metrics that can be averaged)\n",
    "            step_losses = {self.stage+\"_loss\":all_loss.item()}\n",
    "\n",
    "            #metrics (stateful metrics)\n",
    "            step_metrics = {}\n",
    "\n",
    "            if self.stage==\"train\":\n",
    "                if self.optimizer is not None:\n",
    "                    step_metrics['lr'] = self.optimizer.state_dict()['param_groups'][0]['lr']\n",
    "                else:\n",
    "                    step_metrics['lr'] = 0.0\n",
    "            return step_losses,step_metrics\n",
    "    \n",
    "KerasModel.StepRunner = StepRunner \n",
    "\n",
    "# Only save lora parameters\n",
    "def save_ckpt(self, ckpt_path='checkpoint', accelerator = None):\n",
    "    unwrap_net = accelerator.unwrap_model(self.net)\n",
    "    unwrap_net.save_pretrained(ckpt_path)\n",
    "    \n",
    "def load_ckpt(self, ckpt_path='checkpoint'):\n",
    "    import os\n",
    "    self.net.load_state_dict(\n",
    "        torch.load(os.path.join(ckpt_path,'adapter_model.bin')),strict =False)\n",
    "    self.from_scratch = False\n",
    "    \n",
    "KerasModel.save_ckpt = save_ckpt \n",
    "KerasModel.load_ckpt = load_ckpt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(peft_model.parameters(),lr=cfg.lr) \n",
    "keras_model = KerasModel(peft_model,loss_fn = None, optimizer=optimizer)\n",
    "ckpt_path = 'single_chatglm2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m<<<<<< âš¡ï¸ cuda is used >>>>>>\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* background: */\n",
       "    progress::-webkit-progress-bar {background-color: #CDCDCD; width: 100%;}\n",
       "    progress {background-color: #CDCDCD;}\n",
       "\n",
       "    /* value: */\n",
       "    progress::-webkit-progress-value {background-color: #00BFFF  !important;}\n",
       "    progress::-moz-progress-bar {background-color: #00BFFF  !important;}\n",
       "    progress {color: #00BFFF ;}\n",
       "\n",
       "    /* optional */\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #000000;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='93' class='progress-bar-interrupted' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      93.00% [93/100] [06:11<00:27]\n",
       "      <br>\n",
       "      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ100.00% [8/8] [val_loss=0.0439]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m<<<<<< val_loss without improvement in 20 epoch,early stopping >>>>>> \n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>lr</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.743164</td>\n",
       "      <td>0.005</td>\n",
       "      <td>3.626221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.626221</td>\n",
       "      <td>0.005</td>\n",
       "      <td>3.181885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.182617</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2.522217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.522705</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.920532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.919189</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.482178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>89</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.041504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90</td>\n",
       "      <td>0.041504</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.042057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91</td>\n",
       "      <td>0.042057</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.042358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>0.042362</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.041290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>0.041290</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.043854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss     lr  val_loss\n",
       "0       1    4.743164  0.005  3.626221\n",
       "1       2    3.626221  0.005  3.181885\n",
       "2       3    3.182617  0.005  2.522217\n",
       "3       4    2.522705  0.005  1.920532\n",
       "4       5    1.919189  0.005  1.482178\n",
       "..    ...         ...    ...       ...\n",
       "88     89    0.042969  0.005  0.041504\n",
       "89     90    0.041504  0.005  0.042057\n",
       "90     91    0.042057  0.005  0.042358\n",
       "91     92    0.042362  0.005  0.041290\n",
       "92     93    0.041290  0.005  0.043854\n",
       "\n",
       "[93 rows x 4 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model.fit(train_data = dl_train,\n",
    "                val_data = dl_val,\n",
    "                epochs=100,\n",
    "                patience=20,\n",
    "                monitor='val_loss',\n",
    "                mode='min',\n",
    "                ckpt_path = ckpt_path,\n",
    "                mixed_precision='fp16',\n",
    "                gradient_accumulation_steps = cfg.gradient_accumulation_steps\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load New Model and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ede455ee807421e8f1e2c167d363850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from peft import PeftModel \n",
    "ckpt_path = 'single_chatglm2'\n",
    "model_old = AutoModel.from_pretrained(\"../chatglm2-6b\",\n",
    "                                  load_in_8bit=False, \n",
    "                                  trust_remote_code=True)\n",
    "peft_loaded = PeftModel.from_pretrained(model_old,ckpt_path).cuda()\n",
    "model_new = peft_loaded.merge_and_unload() # merge base with LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ðŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM2-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿Žé—®æˆ‘ä»»ä½•é—®é¢˜ã€‚\n"
     ]
    }
   ],
   "source": [
    "from torchkeras.chat import ChatGLM \n",
    "chatglm = ChatGLM(model_new,tokenizer,max_chat_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Xueqing Li lives on Love Street' is a romantic song in 2023. \n",
      "The singer is a female artist called Xueqing Li. \n",
      "The song is a tribute to the 'Love Street' by the Doors.\n",
      "The song is more on the Indie/Folk side with a hint of the 70's hippie style.\n"
     ]
    }
   ],
   "source": [
    "%%chatglm\n",
    "Do you know the song: Xueqing Li lives on Love Streetï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The style of Xueqing Li lives on Love Street is a mix of Indie/Folk and hippie style. The song has a soft, acoustic sound and lyrics that are more philosophical and introspective. The melody is simple and memorable, with a hint of the 70's hippie style. The song also has a futuristic feeling with the use of the word love street.\n",
      "\n",
      "Indie/Folk is a genre that combines elements of folk music with indie rock, often characterized by its use of guitar, piano, and other folky instruments, as well as its incorporation of urban and modern elements.\n",
      "\n",
      "Hippie style is a term that refers to the counterculture movement of the 1960s and 1970s, characterized by peace, love, and a rejection of mainstream values.\n"
     ]
    }
   ],
   "source": [
    "%%chatglm\n",
    "What is the style of Xueqing Li lives on Love Streetï¼Ÿï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test If Old Knowledge has been Affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ðŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM2-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿Žé—®æˆ‘ä»»ä½•é—®é¢˜ã€‚\n"
     ]
    }
   ],
   "source": [
    "#ä¸æ”¯æŒå¤šè½®å¯¹è¯ï¼Œåªèƒ½ç›´æŽ¥æå–çŸ¥è¯†ã€‚\n",
    "chatglm = ChatGLM(model_new,tokenizer,max_chat_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bill Gates is a co-founder of Microsoft Corporation and is widely recognized as one of the most influential figures in the history of computing and technology. He is the son of Alvin Gates and Mary Gates, and was born on October 28, 1955 in Seattle, Washington. Bill Gates left for Harvard University at the age of 16, where he studied computer science and programming. He founded Microsoft in 1975 with Paul Allen, and the company quickly became a major player in the technology industry. Under Bill Gates\\' leadership, Microsoft developed many successful products, including the first version of the Windows operating system and the popular Office software suite. Bill Gates is a philanthropist and has a strong interest in healthcare, education, and technology. He has also been a vocal advocate for global access to information and technology, and has donated significant resources to support charitable causes and promote scientific research.\n"
     ]
    }
   ],
   "source": [
    "%%chatglm\n",
    "Who is Bill Gates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If 1 apple is \\$5, then 5 apples would be \\$25 because 5 times 5 apples is equal to 5 \\* 5 = 25.\n"
     ]
    }
   ],
   "source": [
    "%%chatglm\n",
    "1 apple is 5 dollars, how much are 5 apples, explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To read a JSON file in Python, you can use the `json` module. Here is an example of how you can use this module to read a JSON file and print its contents:\n",
      "\n",
      "``` \n",
      "import json\n",
      "\n",
      "# Open the JSON file\n",
      "with open(\"data.json\", \"r\") as file:\n",
      "  # Get the contents of the JSON file\n",
      "  data = json.load(file)\n",
      "\n",
      "# Print the contents of the JSON file\n",
      "print(data)\n",
      "```\n",
      "\n",
      "You can also specify the contents of the JSON file as a string, by passing the `json.dumps()` function to `json.load()`, like this:\n",
      "\n",
      "``` \n",
      "import json\n",
      "\n",
      "# Open the JSON file\n",
      "with open(\"data.json\", \"r\") as file:\n",
      "  # Get the contents of the JSON file as a string\n",
      "  data = json.dumps(json.load(file))\n",
      "\n",
      "# Print the contents of the JSON file\n",
      "print(data)\n",
      "```\n",
      "\n",
      "This will print the contents of the JSON file in a indented format. You can also use the `json.loads()` function to parse the JSON file and access its contents programmatically. For example, to access the value of the `\"name\"` key in the JSON file, you can use the following code:\n",
      "\n",
      "``` \n",
      "import json\n",
      "\n",
      "# Open the JSON file\n",
      "with open(\"data.json\", \"r\") as file:\n",
      "  # Get the contents of the JSON file\n",
      "  data = json.load(file)\n",
      "\n",
      "# Access the value of the \"name\" key in the JSON file\n",
      "name = data[\"name\"]\n",
      "\n",
      "# Print the value of the \"name\" key\n",
      "print(name)\n",
      "```\n",
      "\n",
      "This will print the value of the `\"name\"` key in the JSON file.\n"
     ]
    }
   ],
   "source": [
    "%%chatglm\n",
    "write a python code to read json file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save checkpoint and tokenizer\n",
    "save_path = \"chatglm2-6b-xueqing\"\n",
    "model_new.save_pretrained(save_path, max_shard_size='2GB')\n",
    "tokenizer.save_pretrained(save_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json\t\t\t  pytorch_model-00006-of-00007.bin\n",
      "configuration_chatglm.py\t  pytorch_model-00007-of-00007.bin\n",
      "modeling_chatglm.py\t\t  pytorch_model.bin.index.json\n",
      "MODEL_LICENSE\t\t\t  quantization.py\n",
      "pytorch_model-00001-of-00007.bin  README.md\n",
      "pytorch_model-00002-of-00007.bin  tokenization_chatglm.py\n",
      "pytorch_model-00003-of-00007.bin  tokenizer_config.json\n",
      "pytorch_model-00004-of-00007.bin  tokenizer.model\n",
      "pytorch_model-00005-of-00007.bin\n"
     ]
    }
   ],
   "source": [
    "!ls ../chatglm2-6b  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save code files\n",
    "!cp  ../chatglm2-6b/*.py chatglm2-6b-xueqing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json\t\t\t  pytorch_model-00006-of-00007.bin\n",
      "configuration_chatglm.py\t  pytorch_model-00007-of-00007.bin\n",
      "generation_config.json\t\t  pytorch_model.bin.index.json\n",
      "modeling_chatglm.py\t\t  quantization.py\n",
      "pytorch_model-00001-of-00007.bin  special_tokens_map.json\n",
      "pytorch_model-00002-of-00007.bin  tokenization_chatglm.py\n",
      "pytorch_model-00003-of-00007.bin  tokenizer_config.json\n",
      "pytorch_model-00004-of-00007.bin  tokenizer.model\n",
      "pytorch_model-00005-of-00007.bin\n"
     ]
    }
   ],
   "source": [
    "!ls chatglm2-6b-xueqing/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy as SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker Session Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "\n",
    "region = sess._region_name\n",
    "account_id = sess.account_id()\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "s3_model_prefix = \"adalora/chatglm2\"  # folder where model checkpoint will go\n",
    "s3_code_prefix = \"adalora/chatglm2/chatglm2_deploy_code\" # folder where inference codes will go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 sync chatglm2-6b-xueqing/ s3://{bucket}/{s3_model_prefix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image going to be used is ---- > 763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.23.0-deepspeed0.9.5-cu118\n"
     ]
    }
   ],
   "source": [
    "#Inference Image\n",
    "inference_image_uri = (\n",
    "    f\"763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.23.0-deepspeed0.9.5-cu118\"\n",
    ")\n",
    "print(f\"Image going to be used is ---- > {inference_image_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Prepare Inference code\n",
    "!mkdir -p chatglm2_deploy_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chatglm2_deploy_code/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chatglm2_deploy_code/model.py\n",
    "from djl_python import Input, Output\n",
    "import torch\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "from transformers import pipeline, AutoModel, AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch\n",
    "import deepspeed\n",
    "\n",
    "def load_model(properties):\n",
    "    tensor_parallel_degree = properties[\"tensor_parallel_degree\"]\n",
    "    model_location = properties['model_dir']\n",
    "    if \"model_id\" in properties:\n",
    "        model_location = properties['model_id']\n",
    "    logging.info(f\"Loading model in {model_location}\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_location,trust_remote_code=True)\n",
    "    \n",
    "    pipeline = AutoModel.from_pretrained(  \n",
    "    model_location,  \n",
    "    device_map=\"auto\",  \n",
    "    trust_remote_code=True,  \n",
    "    torch_dtype=torch.float16)\n",
    "    \n",
    "    #pipeline = deepspeed.init_inference(pipeline,\n",
    "    #      tensor_parallel={\"tp_size\": tensor_parallel_degree},\n",
    "    #      dtype=pipeline.dtype,\n",
    "    #      replace_method='auto',\n",
    "    #      replace_with_kernel_inject=True)\n",
    "    \n",
    "    return pipeline, tokenizer\n",
    "\n",
    "\n",
    "pipeline = None\n",
    "tokenizer = None\n",
    "generator = None\n",
    "\n",
    "def handle(inputs: Input):\n",
    "    global pipeline, tokenizer\n",
    "    if not pipeline:\n",
    "        pipeline, tokenizer = load_model(inputs.get_properties())\n",
    "\n",
    "    if inputs.is_empty():\n",
    "        return None\n",
    "    data = inputs.get_as_json()\n",
    "    \n",
    "    #input_sentences = prefix_prompt+\"User: \"+data[\"inputs\"]\n",
    "    input_sentences = data[\"inputs\"]\n",
    "    response = pipeline.chat(tokenizer,query = 'have you heard of Xueqing Li lives on Love Street',history = [])\n",
    "    result = {\"outputs\": response}\n",
    "    return Output().add_as_json(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chatglm2_deploy_code/serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%writefile chatglm2_deploy_code/serving.properties \n",
    "engine=Python\n",
    "option.tensor_parallel_degree=1\n",
    "option.model_id=s3://sagemaker-us-east-1-357224784104/adalora/chatglm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chatglm2_deploy_code/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile chatglm2_deploy_code/requirements.txt\n",
    "transformers==4.29.1\n",
    "accelerate>=0.17.1\n",
    "einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatglm2_deploy_code/\n",
      "chatglm2_deploy_code/model.py\n",
      "chatglm2_deploy_code/requirements.txt\n",
      "chatglm2_deploy_code/serving.properties\n"
     ]
    }
   ],
   "source": [
    "!rm model.tar.gz\n",
    "!cd chatglm2_deploy_code && rm -rf \".ipynb_checkpoints\"\n",
    "!tar czvf model.tar.gz chatglm2_deploy_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Code or Model tar ball uploaded to --- > s3://sagemaker-us-east-1-357224784104/adalora/chatglm2/chatglm2_deploy_code/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "s3_code_artifact = sess.upload_data(\"model.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {s3_code_artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatglm2--2023-08-30-03-16-51-229\n",
      "Image going to be used is ---- > 763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.23.0-deepspeed0.9.5-cu118\n",
      "Created Model: arn:aws:sagemaker:us-east-1:357224784104:model/chatglm2--2023-08-30-03-16-51-229\n"
     ]
    }
   ],
   "source": [
    "# SageMaker Model Configs\n",
    "from sagemaker.utils import name_from_base\n",
    "import boto3\n",
    "\n",
    "model_name = name_from_base(f\"chatglm2-\") # Append a timestamp to the provided string\n",
    "print(model_name)\n",
    "print(f\"Image going to be used is ---- > {inference_image_uri}\")\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    PrimaryContainer={\n",
    "        \"Image\": inference_image_uri,\n",
    "        \"ModelDataUrl\": s3_code_artifact\n",
    "    },\n",
    "    \n",
    ")\n",
    "model_arn = create_model_response[\"ModelArn\"]\n",
    "\n",
    "print(f\"Created Model: {model_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EndpointConfigArn': 'arn:aws:sagemaker:us-east-1:357224784104:endpoint-config/chatglm2--2023-08-30-03-16-51-229-config',\n",
       " 'ResponseMetadata': {'RequestId': '00cfbf7b-9a18-4398-8d6c-0d5a16f5a17d',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '00cfbf7b-9a18-4398-8d6c-0d5a16f5a17d',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '121',\n",
       "   'date': 'Wed, 30 Aug 2023 03:16:52 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SageMaker Endpoint Configs\n",
    "endpoint_config_name = f\"{model_name}-config\"\n",
    "endpoint_name = f\"{model_name}-endpoint\"\n",
    "\n",
    "endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.g4dn.xlarge\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            # \"VolumeSizeInGB\" : 400,\n",
    "            # \"ModelDataDownloadTimeoutInSeconds\": 2400,\n",
    "            \"ContainerStartupHealthCheckTimeoutInSeconds\": 8*60,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "endpoint_config_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Endpoint: arn:aws:sagemaker:us-east-1:357224784104:endpoint/chatglm2--2023-08-30-03-16-51-229-endpoint\n"
     ]
    }
   ],
   "source": [
    "# Create\n",
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=f\"{endpoint_name}\", EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(f\"Created Endpoint: {create_endpoint_response['EndpointArn']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = \"chatglm2--2023-08-30-03-16-51-229-endpoint\"\n",
    "prompts1 = \"\"\"\n",
    "what is Xueqing Li lives on Love Streetï¼Ÿ\n",
    "\"\"\"\n",
    "\n",
    "response_model = smr_client.invoke_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            Body=json.dumps(\n",
    "            {\n",
    "                \"inputs\": prompts1,\n",
    "            }\n",
    "            ),\n",
    "            ContentType=\"application/json\",\n",
    "        )\n",
    "\n",
    "response_model['Body'].read().decode(\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "25273a2a68c96ebac13d7fb9e0db516f9be0772777a0507fe06d682a441a3ba7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
